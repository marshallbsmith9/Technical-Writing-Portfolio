**Author:** Marshall Smith

# Project Description
This paper presents a comprehensive academic analysis of GPT-4, a large language model developed by OpenAI. The report evaluates GPT-4 from both a technical and societal perspective, focusing on how the model is trained, how its performance is measured, how access is licensed, and what ethical risks accompany its deployment.

The project demonstrates an understanding of modern generative AI systems and their real-world implications across education, healthcare, software development, and policy.

## Key Areas of Analysis
1. Model Training

- Large-scale pre-training on publicly available and licensed data
- Fine-tuning using Reinforcement Learning from Human Feedback (RLHF)
- Supervised learning for task-specific improvement
- Discussion of infrastructure, compute scale, and transparency limitations

2. Accuracy and Benchmark Performance

- Evaluation using industry-standard benchmarks (e.g., MMLU, HumanEval)
- Comparison against GPT-3.5 and average human performance
- Analysis of strengths, reasoning improvements, and known failure modes

3. Licensing and Access

- Closed-source nature of GPT-4
- API-based access and subscription models
- Implications for developers, researchers, and reproducibility

4. Ethical Considerations

- Bias and fairness risks
- Hallucinations and misinformation
- Environmental impact of large-scale AI training
- Governance and responsible deployment challenges

## Skills Demonstrated
- Technical understanding of large language models
- AI performance evaluation using benchmarks
- Critical analysis of licensing and access models
- Ethical reasoning in applied AI systems
- Formal academic and technical writing
